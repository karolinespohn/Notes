# Hypothesis Testing
- For hypothesis testing, the first step is stating a **null** and an **alternative hypothesis**
- An $\alpha$ level, which is the probability of falsely rejecting $H_0$, is chosen
- The test statistic is calculated to find the $p$-value
- If $p \le \alpha$, the $H_0$ is rejected, otherwise there is insufficient evidence to reject $H_0$
- **Type I errors** occur when $H_0$ is rejected despite being true
- **Type II errors** occur when $H_0$ is not rejected, despite $H_A$ being true
 ![[errorTypes.png|400]]
## $z$-Tests 
- The $z$ test is used, when the population mean $\mu$ and the standard deviation $\sigma$ are known
- The $z$-confidence interval is given by: 
$$\overline X\pm z_{\frac{1-\alpha}2}\frac{\sigma}{\sqrt{n}}$$
- The $z$-test is given by: 
$$z=\frac{\overline X -\mu_0}{\frac{\sigma}{\sqrt n}}$$
- The following $H_1$s have the following rejection region

| $H_1$            | Rejection Region                       |
| ---------------- | -------------------------------------- |
| $\mu \neq \mu_0$ | $\mid z \mid \ge z_{\frac{1-\alpha}2}$ |
| $\mu > \mu_0$    | $z \ge z_{1-\alpha}$                   |
| $\mu < \mu_0$    | $z \le z_\alpha = -z_{1-\alpha}$       |
## Student $t$-Distribution
- $t$-Tests are used for test statistics with a mean $\mu$ and an unknown $\sigma$
- The $t$-test is given by: 
$$t = \frac{\overline X -\mu}{\frac{s}{\sqrt n}} \sim \text{Student}-t(df = n -1)$$
## CI & 2-Sided Tests
- A 2-sided test rejects $H_0 = \mu = \mu_0$ when the value $\mu_0$ falls outside a level $1-\alpha$ confidence interval for $\mu$
## $t$-Tests 
- For different $t$-tests, the formula is slightly different for single sample, paired samples and independent samples
### Paired $t$-Test
- The **paired $t$-Test** tests the relationship between 2 linked samples
- $H_0$ is given by: 
$$H_0: \mu_d = \mu_1 - \mu_2 = \Delta_0$$
- The test statistics are given by: 
$$t = \frac{\overline d - \Delta_0}{\frac{s}{\sqrt n}}$$
- The following $H_1$s have the following rejection region

| $H_1$                 | Rejection Region                             |
| --------------------- | -------------------------------------------- |
| $\mu_d \neq \Delta_0$ | $\mid t \mid \ge t_{1-\frac \sigma 2, n -1}$ |
| $\mu_d > \delta_0$    | $t \ge t_{1-\alpha, n-1}$                    |
| $\mu_d < \Delta_0$    | $t \le t_{\alpha, n-1} = -t_{1-\alpha, n-1}$ |
### Independent Samples
- The **independent samples $t$-test** tests the relationship between 2 independent populations
- The null-hypothesis states $H_0 : m_1 = m_2$ and the alternative hypothesis $H_1: m_1 \neq m_2$
# Linear Regression
- A simple linear regression model is given by
$$Y = \beta_0 + \beta_1 X + \varepsilon$$
- A common approach to estimating the coefficients is **ordinary least squares**
$$\hat y= \hat \beta_0 + \hat \beta_1 x$$
$$\min\sum_ie_i^2=\min \sum_i\left (y_i- (\hat \beta _0 + \hat \beta _1 x_i) \right)^2$$
## Residual Sum of Squares (RSS)
- RSS is the sum of squared differences between the points and the regression line
- It is a measure of how well the line fits the data and an estimator is given by:
$$RSS = \sum_{i =1}^n(y_i-\hat y_i)^2$$
- The total sum of squares is the sum of the Explained Sum of Squares and the Residual sum of squares
$$
\begin{align}
\sum(y-\overline y)^2 &= \sum (\hat y - \overline y)^2  &{}+{}& \sum (y - \hat y)^2a \\
TSS & = ESS &{}+{}& RSS \\
\text{Total Deviation} & = \text{Explained Deviation} &{}+{}& \text{Unexplained Deviation}

\end{align}
$$
## $R^2$ 
- $R^2$ measures the proportion of the variation in $y$ that is explained by the variation in $x$
$$ESS = \sum_{i =1}^n (\hat y_i - \overline y)^2$$
$$TSS = \sum_{i = 1}^n(y_i - \overline y)^2 = ESS + RSS$$
$$R^2 = \frac{TSS - RSS}{TSS} = 1 - \frac{RSS}{TSS} = \frac{ESS}{TSS}$$