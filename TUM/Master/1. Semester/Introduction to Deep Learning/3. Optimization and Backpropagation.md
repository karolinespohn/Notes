- In the forward pass, the computations in the neural network are evaluated
![[computational graph.png|400]]
- In the backward pass, the loss is computed and propagated backwards through the network, determining for each connection how much it contributed to the error and updating the weights
- The chain rule $\frac{\delta f}{\delta y} = \frac{\delta f}{\delta d} \cdot \frac{\delta d}{\delta y}$ is used for
# Gradient Descent
- A gradient is a vector of **partial derivatives**
$$\nabla _xf(x) = \left(\frac{\partial g}{\partial x_1},..., \frac{\partial g}{\partial x_k}\right)$$
- Gradient descent is the optimization method used to find the best possible weights: 
	1. First, the **gradient** $(\nabla f)$ is found, which points into the direction of the fastest increase of the loss function
	2. Then, a step is taken into the **negative direction** to minimize the loss
	3. The weights are then updated by computing
$$\text{New Weights = Old Weights - (Learning Rate $\cdot$ Gradient)}$$
$$W' = W - \alpha \nabla wf(W)$$
# Regularization
![[under & overfitting.png]]
- During training, it is desirable to avoid overfitting or underfitting
- A model can be prevented from overfitting through **regularization**
- Regularization is any strategy that aims to lower validation error and increase training error
- $L_1$ and $L_2$ regularization add a term to the loss function: 
$$\sum_{i = 1}^n(x_i\theta_{ji} - y_i)^2 + \lambda R(\theta)$$
- Where $R(\theta)$ is...
	- ...$\sum_{i = 1}^n |\theta_i|$ for $L_1$ regularization
	- ...$\sum_{i = 1}^n\theta_i^2$
- $L_1$ regularization enforces **sparcity**, thereby only taking into account few key features
- L_2 regularization enforces the values to be **similar**, taking into account all information to make decisions
