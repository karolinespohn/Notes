# Regex
- Regular Expressions are an algebraic notation for characterizing a set fo strings
- Substitutions can be made by through `re.sub`
```
re.sub(r"cherry", r"apricot", string)
```
- Conversions can be made like so: 
```
re.sub(r"(\d{2})/(\d{2})/(\d{4}), r"\2-1-\3", string)
```
# Definitions
- The sentence...
```
Hello, how are you?
```
- ...has $4$ words without counting punctuation and $6$ wirds with punctuation
- For the sentence...
```
Hello, uh, how are you
```
- ... it is more difficult to count the words, since it is not clear if `uh` counts
- For the sentence...
``` 
His cat is nicer than the other cats.
```
- ... it is unclear, whether `cat` and `cats` should be counted separately
- A **type** is an element of the vocabulary $V$
- A **token** is an instance of that type in a text
- The number of tokens will be refered to as $N$
- Heap's law calculates the number of distinct words in a text of length $n$ as: 
$$|V| = kN^\beta$$
- Where $K$ and $\beta$ are determined empirically
- In a language, **function words** (a, you, the, can, is,...) can be distinguished from **content words** (nouns, verbs, adjectives)
- Sometimes, different values are defined for $\beta$
- Language can depend on **context** (social, geographic,...)
## Tokenization
- Tokenization is the segmentation of texts into words, and it is associated with different challenges
	- Are capitalized tokens the same as non-capitalized tokens?
	- Are words like "San Francisco" one or two tokens?
	- How are emojis counted?
	- In languages like Chinese and Japanese, there are no spaces between words
	- ...
- Treating all issues of tokenization with rules and automata fast is complicated
- Therefore **subwords/morphenes** are used, meaning the minimal components that have some meaning
```
fox: -> fox
cats: -> cat-s
Doc worked carefully washing the glasses -? Doc work-ed care-ful-ly wash-ing the glass-es
```
- The **root** is the central morpheme of the word, supplying the main meaning
- **Affixes** are bits and pieces adhering to the stem
- **Inflection morphemes** are related to grammar/syntax (`-s`, `-es`, `-ed`,...)
- **Derivational morphemes** transfer to different grammatical classes (`care` $\to$ `careful`, `carefully`)
- The number of morphenes per word depends on the language: Cantonese usually just has one, Koryak has many
### Tokenization on Character-Level
- Unicode has $155,000$ different characters
- **Byte Pair Encoding** is the iterative merging of frequent pairs of characte
- The most frequent character n-gram pairs in words create a new n-gram
- With iteration, there is word segmentation into character n-grams