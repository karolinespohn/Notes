- Zeitliche Folgen von Zufallsprozessen heissen **Stochastische Prozesse**
# Markov Ketten
- Bei Markov-Ketten darf der naechste Zustand vom aktuellen Zustand abhaengen, aber nicht von der Historie
- Eine endliche Markovkette ueber der Zustandsmenge $S = \{0, 1, ..., n-1\}$ besteht aus:
	- Einer unendlichen Folge von Zufallsvariablen $(X_t)_{t \in \mathbb N_0}$ mit der Wertemenge $S$ 
	- Einer Startverteilung $q_0^T \in \mathbb R^n$ mit nicht-negativen Komponenten deren Summe 0 ist
	