- Nicht die Ereignisse an sich, sondern die **Auswirkungen** des Ereignis sind relevant
# Definition
- In einem Wahrscheinlichkeitsraum auf der Ergebnismenge $\Omega$ nennen wir eine Abbildung $X: \Omega \to \mathbb R$ **Zufallsvariable**
- Zufallsvariablen ueber einem endlichen oder abzaehlbaren $\Omega$ heissen **diskret**
- Der Wertebereich bei diskreten Zufallsvariablen ist endlich und definiert wiefolgt: 
$$W_X = X(\Omega) = \{x \in \mathbb R \mid \exists \, \omega \in \Omega \text{ mit } X(\omega) = x\}$$
# Dichte- und Verteilungsfunktion
- Die **Dichtefunktion** der Zufallsvariablen $X$ ist deiniert wiefolgt:
$$f_X: \mathbb R \ni x \mapsto \Pr[X = x] \in [0, 1]$$
- Die **Verteilungsfunktion** der Zufallsvariablen $X$ ist definiert wiefolgt: 
$$F_X: \mathbb R \ni x \mapsto \Pr[X \le x] = \sum_{x' \in W_X: \, x' \le x}\Pr[X = x'] \in [0, 1]$$
# Erwartungswert
- Der **Erwartungswert** beschreibt das **Mittel der Werte**, die eine Zufallsvariable annimmt
- Der Erwartungswert $\mathbb E$ zu einer Zufallsvariable $X$ ist (unter Annahme der absoluten Konvergenz) definiert wiefolgt: 
$$\mathbb E[X]:= \sum_{x \in W_X} x \cdot \Pr[X = x] = \sum_{x \in W_X} x \times f_X(x)$$
## Monotonie
- Fuer die Zufallsvariablen $X$ und $Y$ ueber dem Wahrscheinlichkeitsraum $\Omega$ mit $X(\omega) \le Y(\omega)$ gilt: 
$$\mathbb E [X] \le \mathbb E[Y]$$
- Falls $a \le X(\omega) \le b$ gilt gilt somit auch:
$$a \le \mathbb E[X]\le b$$
## Rechenregeln
- Sei $X$ eine Zufallsvariable
- Auf $X$ kann man eine Funktion anwenden: 
$$Y := f(X) = f \circ X$$
- Fuer $X$ und $a, b \in \mathbb R$ gilt: 
$$\mathbb E[a \cdot X + b] = a * \mathbb E[X] + b$$

- Falls $W_X \subseteq \mathbb N_0$, dann gilt: 
$$\mathbb E[X] = \sum_{i = 1}^{\infty} P[X \ge i]$$
## Erwartungswert bedingter Zufallsvariablen
- Sei $X$ eine Zufallsvariable und $A$ ein Ereignis mit $\Pr[A] >0$, so besitzt die **bedingte Zufallsvariable** die folgende Dichte:
$$f_{A|X}(x):= \Pr[X = x|A] = \frac{\Pr['X = x' \cap A]}{\Pr[A]}$$
- Der Erwartungswert ist dementsprechend: 
$$\mathbb E[X|A] := \sum_{x \in W_X}x \cdot f_{X|A}(x)$$
- Fuer paarweise disjunkte Ereignisse $A_1,...,A_n$ mit $A_1\cup ...\cup A_n = \Omega$ und $\Pr[A_i] > 0$ fuer $i = 1,...,n$ gilt: 
$$\mathbb E[X] = \sum_{i = 1}^n \mathbb E[X|A_i]\cdot \Pr[A_i]$$
# Varianz
- Mit der **Varianz** misst man die **Streuung** einer Wahrscheinlichkeitsdichte um ihren Erwartungswert
- Fuer eine beliebige Zufallsvariable $X$ ist die Varianz definiert wiefolgt: 
$$\text{Var}[X] = \mathbb E[(X - \mu)^2] = \mathbb E[X^2] - \mathbb E[X]^2 = \sum_{x \in W_X}(x - \mu)^2\cdot \Pr[X = x]$$
- Fuer $X$ und $a, b \in \mathbb R$ gilt: 
$$\text{Var}[a \cdot X + b] = a^2 \cdot \text{Var}(X)$$
- Die **Standardabweichung** ist definiert wiefolgt: 
$$\sigma : = \sqrt{\text{Var}[X]}$$
$$\sum_1^{\infty} \frac1{k^2}$$
## Mehrere Zufallsvariablen
- Fuer 2 Zufallsvariablen $X$ und $Y$ wird die **gemeinsame Dichte** berechnet wiefolgt: 
$$f_{X, Y} (x, y)=\Pr[X = x, Y = y] $$
- Die **Randdichten** lauten wiefolgt: 
$$f_X(x) = \sum_{y \in W_Y} f_{X, Y}(x, y)$$
$$f_Y(y) = \sum_{y \in W_X} f_{X, Y}(x, y)$$
- Die **gemeinsame Verteilung** ist definiert wiefolgt: 
$$F_{X, Y} (x, y) = \Pr[X \le x, Y \le y]$$
- Die **Randverteilungen** lauten 
### Unabhaengigkeit
$$F_X (x) = \sum_{x' \le x}f_X(x') = \sum_{x'\le x}\sum_{y \in W_Y}f_{X, Y}(x', y)$$
- Zufallsvariablen $X_1,...,X_n$ heissen **unabhaengig**, wenn gilt
$$\Pr[X_1 = x_1, ..., X_n = x_n] = \Pr[X_1 = x_1] \cdot...\cdot \Pr[X_n = x_n]$$
#### Zufallsvariablen in Mengen
- Sind $X_1, ..., X_n$ unabhaengige Zufallsvariablen, und $S_1,...,S_n$ Mengen, fuer die gilt $S_i \subseteq W_{X_i}$ 
- Dann sind die Ereignisse $\text{"}X_1 \in S_1\text{"}, ..., \text{"}X_n \in S_n \text{"}$ unabhaengig
#### Zufallsvariablen und Funktionen
- Fuer reellwertige Funktionen $f_1,...,f_n$ gilt: 
- Sind Zufallsvariablen $X_1,...,X_n$ unabhaengig, dann auch $f_1(X_1),...,f_n(X_n)$ 
### Zusammengesetzte Zufallsvariablen
- Seien $X$ und $Y$ unabhaengige Zufallsvariablen und $Z = X + Y$
- Die **Verteilung** von $Z$ lautet:
$$f_Z(z) = \sum_{x \in W_X}f_X(x) \cdot f_Y(y-x)$$
### Linearitaet des Erwartungswertes
- Fuer Zufallsvariablen $X_1,...,X_n$ und $X: = a_1X_1 + ... + a_nX_n$  gilt
$$\mathbb E[X]=a_1\mathbb E[X_1] + ... + a_n\mathbb E[X_n]$$
### Multiplikativitaet des Erwartungswertes
- Fuer unabhaengige Zufallsvariablen $X_1, ..., X_n$ gilt:
$$\mathbb E[X_1\cdot ... \cdot X_n] = \mathbb E[X_1] \cdot ... \cdot \mathbb E[X_n]$$
### Additivitaet der Varianz
- Fuer unabhangige Zufallsvariablen $X_1,...,X_n$ und $X:= X_1 + ... + X_n$ gilt:
$$\text{Var}[X] = \text{Var}[X_1]+...+\text{Var}[X_n]$$
## Indikatorvariable
- Eine **Indikatorvariable** $I_A$ ist definiert wiefolgt
$$I_A= \begin{cases}
1 \quad & \text{falls } A \text{ eintritt}\\
0 \quad & \text{sonst}
\end{cases}$$