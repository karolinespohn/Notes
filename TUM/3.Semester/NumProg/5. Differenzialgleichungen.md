- Fuer eine bessere Zusammenfassung empfehle ich die Notizen von [Anton](https://github.com/AntonScheitler/Notes)
# Grundlagen
- Differenzialgleichungen erlauben, einer Funktion ueber das Verhalten ihrer Ableitungen zu definieren
- Haeufig kann man Differenzialgleichugnen nicht analytisch, sondern nur numerisch loesen
- Man unterscheidet zwischen gewoehnlichen Differenzialgleichungen mit einer Variable und partiellen Differenzialgleichungen mit mehreren Variablen
- Sei $f$ eine Funktion und $\dot f$ ihre Ableitung
- Eine Differenzialgleichung in Abhaengigkeit von der Zeit $t$ laesst sich aufstellen wiefolgt:
$$\dot f(t) = F(t, f(t))$$
# Approximationsverfahren
- Um eine Differenzialgleichung $\dot f(t) = F(t, f(t))$ zu approxiomiert wird sie diskretisiert
- Jedes Vorlommen einer Ableitung wird durch den Differenzialquotienten ueber ein kleines Intervall $\delta t$ $\frac{y(t+\delta t)-y(t)}{\delta t}$ ersetzt
- TODO: verfahren
## Eulersche Methode
- Ein Startpuntk $y_k$ zum Zeitpunkt $t_k$ ist gegeben
- Um einen Wert $y_{k + 1}$ zum Zeitpunkt $t_{k + 1} = t_0 + (k + 1) \cdot \delta t$ zu ermitteln, werden der Differenzenquotient $f(t_k, y_k)$, sowie der Wert $y_k$ zum vorherigen Zeitpunkt $t_k$ verwendet
- Es gilt: 
$$y_{k + 1} = y_k + \delta t \cdot f(t_k, y_k)$$

![[Screenshot 2024-01-06 at 18.10.27.png|300]]
## Heun'sche Methode
- Mittels der euler'schen Methode bestimmt man die Werte $y_k$ und $y_{k+1}$ bestimmt
- Man ermittelt den Durchschnitt der Steigungen $f(t_k, y_k)$ und $f(t_{k + 1}, y_{k + 1})$ um die Steigung $t_k$ besser zu approximieren
- Hierbei verdoppelt sich die Anzahl der Auswertungen von $f$
## Runge-Kutta Verfahren
- Zwischen den Zeitpunkten $t_k$ und $t_{k +1}$ definiert man zwei weitere Stuetzpunkte, sodass man insgesamt $4$ Punkte hat
- Man verwendet nun alle 4 Punkte fuer eine bessere Approximation fuer die Steigung zum Zeitpunkt $t_k$
- Die Anzahl der Auswertungen von $f$ vervierfacht sich
## Mehrschrittmethoden
- Man verwendet $f(t_k, y_k)$ und $f(t_{k-1}, y_{k-1})$ um $y_{k+1}$ zu ermitteln
- Man findet somit ein genaueres $y_{k + 1}$, ohne $f$ oefter auswerten zu muessen
- Man berechnet $y_{k+1}$ wiefolgt:
$$y_{k + 1} = y_k + \frac{\delta t}{2} \left (3f(t_k, y_k) - f(t_{k - 1}, y_{k - 1}) \right)$$
- Weil beim ersten Schritt kein Vorgaenger besteht, verwendet man fuer den einstieg eine Einschrittmethode
# Qualitaetsmessung
- Man bewertet ein Approximationsverfahren anhand der Konsistenz und Konvergenz
## Konsistenz
- Der lokale Fehler an einem Punkt $t_k$ bezeichnet den Fehler, der durch die Diskretisierung an einem Punkt entsteht
- Geht der lokale Fehler gegen 0 wenn $\delta t$ gegen 0 geht, ist ein Verfahren konsistent
## Konvergenz
- Der globale Fehler bezeichnet den maximalen Fehler der Summe aller Approximationen
- Geht der globale Fehler gegen 0, falls $\delta t$ gegen 0 geht, ist ein Verfahren konvergent
## Bewertung von Verfahren
- Euler, Heun und Runge-Kutta sind konsistent und konvergent