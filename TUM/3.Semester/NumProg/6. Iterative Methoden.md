# Iterative Methoden
- Kann man ein Gleichungssystem $Ax= b$ nicht direkt loesen, verwendet man iterative Verfahren
- Dabei ist $x^{(i)}$ eine die approximierte Loesung im $i$-ten Schritt
## Residuum 
- Als Startpunkt dient das Residuum $r^{(i)}$ einer Loesung $x^{(i)}$, das definiert ist wiefolgt:
$$r^{(i)}:= b-Ax^{(i)}= Ax-Ax^{(i)}= -Ae^{(i)}$$
- $r^{(i)}$ dient als Richtungsvektor dafuer, wohin  $x^{(i)}$ vergenauert werden soll
## Richardson
- Das Residuum wird auf die derzeitige Loesung addiert, um den naechsten Approximanten zu erhalten
$$x^{(i + 1)} = x^{(i)} + r^{(i)}$$
## Jacobi
- Fuer jedes $k \in \{1,...,n\}$ berechnet man unter Betracht des Residuums einen Aktualisierungswert $y_k$
$$y_k = \frac{1}{a_{kk}} \cdot r_k^{(i)}$$
- Dieser wird dann auf die aktuelle Loesung addiert:
$$x^{(i + 1)} = x^{(i)} + y$$
## Gauss-Seidel
- Erneut berechnet man fuer jedes $k \in \{1,...,n\}$ berechnet man unter Betracht des Residuums einen Aktualisierungswert $y_k$, wobeit das Residuum anders bestimmt wird:
$$r_k^{(i)} = b_k - \sum_{j = 1}^{k - 1} a_{kj}x_j^{(i + 1)} - \sum_{j = k}^{n}a_{kj}x_j^{(i)}$$
$$y_k = \frac{1}{a_{kk}} \cdot r_k^{(i)}$$
$$x^{(i + 1)} = x^{(i)} + y$$
## Dampening und Over-Relaxation
- Dampening und over-relaxation beschreiben die Multiplikation des Aktualisierungsvektors mit einem Skalar $\alpha$
- Beim Dampening gilt $0 < \alpha < 1$ und bei over-relaxation gilt $1 < \alpha < 2$
$$x^{(i + 1)} = x^{(i)} + \alpha y$$
