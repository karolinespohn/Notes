- Die Beispiele stammen von mir, und muessen dementsprechend nicht richtig sein, mir helfen sie jedoch beim Verstaendnis
# Differentialrechnung in $d \ge 1$
- Sei $D \subseteq \mathbb R^n$ offen, sei $f: D \to \mathbb R^m$ eine Funktion und sei $x_0 \in D$ 
- $f$ heisst in $x_0$ differenzierbar mit der Ableitung $A \in M_{n \times m}(\mathbb R)$, falls gilt:
$$\lim_{x \to x_0} \frac{f(x) -f (x_0)-(x-x_0)\cdot A}{||x-x_0||} = 0$$
- Die Ableitung ist eindeutig
## Zweite Ableitung
- Fuer eine Funktion $f: \mathbb R^n \to \mathbb R^m$, ist die Ableitung eine Funktion $f': \mathbb R^n \to M_{n \times m}(\mathbb R)$, wobei der Raum der Matritzen $M_{n \times m}(R)$ isomorph zu $\mathbb R^{n \times m}$ ist
$$f': \mathbb R^n \to \mathbb R^{n \cdot m}$$
- Die zweite Ableitung ist definiert wiefolgt:
$$\mathbb R^n \to M_{n \times (n \cdot m)} \approx R^{n^2 m}$$
# Patrielle Differentiale
- Sei $f: R^n \subseteq D \to \mathbb R^m$ und sei $x = (x_1,...,x_n)$
- Wir schreiben: 
$$f(x)=\begin{pmatrix}f_1(x)\\ f_2(x)\\ \vdots \\ f_m(x)
\end{pmatrix}$$
- Fuer $i = 1, .., n$ und $j = 1,...,m$
$$\frac{\mathrm d f_j}{\mathrm d x_i}:=
\lim_{h \to 0}
\frac{f_j(x_1,...,x_{i} + h,..., x_n)-f_j(x)}{h}$$
- Partielle Ableitung funktioniert wie normale Ableitung, wobei wir alle Variablen, nach denen nicht abgeleitet wird, als konstant betrachten
- Ist $f$ im Punkt $x$ differenzierbar mit der Ableitung $A$ ist, dann existieren alle partiellen Ableitungen und $\forall i,j: A_{i,j}= \frac{d f_j}{\mathrm d x_i}$
###### Beispiel: Patrielle Differentiale
- Wir definieren $f$ wiefolgt:
$$f\left(\begin{pmatrix}x\\y\end{pmatrix}\right ) = \frac 1h
=\begin{pmatrix}
2x \\
3y \\
x^2 + y
\end{pmatrix}$$
- $i=1, 2$, da wir 2 Variablen haben, nach denen wir ableiten koennen, $j= 3$, da wir in $\mathbb R^3$ abbilden
- Es gilt:
$$\frac{\mathrm d f_1}{\mathrm dx_i}= \frac 1h \left(\begin{pmatrix}
2x + 2h \\ 3y \\ x^2 + 2xh + 0 + y
\end{pmatrix} - \begin{pmatrix}
2x \\ 3y \\ x^2 + y
\end{pmatrix}\right) =
\frac 1h \begin{pmatrix}
2h\\0\\2xh
\end{pmatrix}
=
\begin{pmatrix}
2\\0 \\2x
\end{pmatrix}$$
$$\frac{\mathrm d f_1}{\mathrm dx_i}= \begin{pmatrix}
0\\
3 \\
1
\end{pmatrix}$$
## Hess Matrix
- Sei $f: D \subseteq \mathbb R^n \to \mathbb R$ eine zweimal differenzierbare Funktion
- Die zweite Ableitung von $f$ ist eine $n \times n$ Matrix namens Hess Matrix
- Den Eintrag an Stelle $i,j$ bezeichnet man $\frac{d^2 f}{d x_ix_j}$ oder $\frac{\delta^2f}{\delta x_i^2}$ falls $i = j$
###### Beispiel
- Ich schreibe als $f_{ab}$ eine Funktion $f$, zunaechst nach $a$ und dann nach $b$ abgeleitet
- Die Hess Matrix einer Funktion $f$ mit den Variablen $x, y, z$ sieht aus wiefolgt
$$\begin{pmatrix}
f_{xx} & f_{xy} & f_{xz} \\
f_{yx} & f_{yy} & f_{yz} \\
f_{zx} & f_{zy} & f_{zz}
\end{pmatrix}$$
## Satz von Schwarz
- Seinen $D \subseteq \mathbb R$ offen, und $f: D \to \mathbb R$ zweimal stetig differenzierbar, gilt:
$$\forall x\in D: \space i, j=1,...n: \frac{\mathrm d^2f}{\mathrm d x_ix_j}= \frac{\mathrm d^2f}{\mathrm d x_jx_i}$$
- Die Hess Matrix ist also immer symmetrisch
# Definitionen
## Gradient
- Sei $D \subseteq \mathbb R^n$ offen, und $f:D \to \mathbb R^n$ differenzierbar
- Man nennt die Ableitung den Gradient von $f$
## Divergenz
- Sei $D \subseteq \mathbb R^n$ offen und $f: D \to \mathbb R^n$ differenzierbar, so ist die Divergenz:
$$\sum_{j = 1}^n \frac{\delta f_j}{\delta x_j}$$
## Laplacian
- Sei $D \in R^n$ und $f: D \to \mathbb R^n$ und zweimal differenzierbar, so ist der Laplacian von $f$
$$\sum_{j = 1}^n\frac{\delta^2f}{\delta x^2_j}$$