- Die Beispiele stammen von mir, und muessen dementsprechend nicht richtig sein, mir helfen sie jedoch beim Verstaendnis
# Differentialrechnung in $d \ge 1$
- Sei $D \subseteq \mathbb R^n$ offen, sei $f: D \to \mathbb R^m$ eine Funktion und sei $x_0 \in D$ 
- $f$ heisst in $x_0$ differenzierbar mit der Ableitung $A \in M_{n \times m}(\mathbb R)$, falls gilt:
$$\lim_{x \to x_0} \frac{f(x) -f (x_0)-(x-x_0)\cdot A}{||x-x_0||} = 0$$
- Die Ableitung ist eindeutig

## Zweite Ableitung
- Fuer eine Funktion $f: \mathbb R^n \to \mathbb R^m$, ist die Ableitung eine Funktion $f': \mathbb R^n \to M_{n \times m}(\mathbb R)$, wobei der Raum der Matritzen $M_{n \times m}(R)$ isomorph zu $\mathbb R^{n \times m}$ ist
$$f': \mathbb R^n \to \mathbb R^{n \cdot m}$$
- Die zweite Ableitung ist definiert wiefolgt:
$$\mathbb R^n \to M_{n \times (n \cdot m)} \approx R^{n^2 m}$$
### Fall $m = 1$
- Die zweite Ableitung ist $\in R^{n \times n}$
-  Fuer $i, j = 1,...,n$ ist die zweite partielle Ableitung $\frac{\delta^2f}{\delta x_i x_j}= \frac{\delta\left(\frac{\delta f}{\delta x_j}\right)}{\delta x_i}$
- Falls $i = j$ schreibt man $\frac{\delta^2f}{\delta x_i^2}$ 
# Patrielle Differentiale
- Sei $f: R^n \subseteq D \to \mathbb R^m$ und sei $x = (x_1,...,x_n)$
- Wir schreiben: 
$$f(x)=\begin{pmatrix}f_1(x)\\ f_2(x)\\ \vdots \\ f_m(x)
\end{pmatrix}$$
- Fuer $i = 1, .., n$ und $j = 1,...,m$
$$\frac{\mathrm d f_j}{\mathrm d x_i}:=
\lim_{h \to 0}
\frac{f_j(x_1,...,x_{i} + h,..., x_n)-f_j(x)}{h}$$
- Partielle Ableitung funktioniert wie normale Ableitung, wobei wir alle Variablen, nach denen nicht abgeleitet wird, als konstant betrachten
## Satz ueber verschiedene Ableitungen in einem Punkt
- Ist $f$ im Punkt $x$ differenzierbar mit der Ableitung $A$ ist, dann existieren alle partiellen Ableitungen und $\forall i,j: A_{i,j}= \frac{d f_j}{\mathrm d x_i}$
## Fall $m = 1$
- Falls $f:D \to \mathbb R$ ist, dann ist die erste Ableitung ein $n$-Dimensionaler Vektor
- Fuer $i=1,...,n$ ist die partielle Ableitung $\frac{\delta f}{\delta x_i}(x_0)$:
$$\lim_{h \to 0}\frac{f(x_0+hv_i)-f(x_0)}{h}$$
- $v_i$ ist dabei ein Vektor, dessen $i$-ter Eintrag $1$ ist und dessen uebrige Eintraege $0$ sind
- Wir schreiben nun $Df$ fuer die Ableitung von $f$
### Satz ueber verschiedene Ableitungen in einem Punkt
- Falls $f$ in $x_0$ differenzierbar ist,  existieren alle partiellen Ableitungen $\frac{df}{dxi}$ und die partiellen Ableitungen entsprechen den Eintraegen im Vektor $Df(x_0)$
- Falls die partiellen Ableitungen ueberall in $D$ existieren und ueberall stetig sind, ist auch $f$ in $D$ stetig differenzierbar
#### zweite Ableitungen
- Falls $\forall x_0 \in D, \forall i, j$ gilt: $\frac{d^2f}{dx_ix)j}$ ist in $D$ stetig, dann ist $f$ in $D$ zweimal differenzierbar
- $D^2f$ (die Hesse Matrix) ist Symmetrisch
###### Beispiel: Patrielle Differentiale
- Wir definieren $f$ wiefolgt:
$$f\left(\begin{pmatrix}x\\y\end{pmatrix}\right ) = \frac 1h
=\begin{pmatrix}
2x \\
3y \\
x^2 + y
\end{pmatrix}$$
- $i=1, 2$, da wir 2 Variablen haben, nach denen wir ableiten koennen, $j= 3$, da wir in $\mathbb R^3$ abbilden
- Es gilt:
$$\frac{\mathrm d f_1}{\mathrm dx_i}= \frac 1h \left(\begin{pmatrix}
2x + 2h \\ 3y \\ x^2 + 2xh + 0 + y
\end{pmatrix} - \begin{pmatrix}
2x \\ 3y \\ x^2 + y
\end{pmatrix}\right) =
\frac 1h \begin{pmatrix}
2h\\0\\2xh
\end{pmatrix}
=
\begin{pmatrix}
2\\0 \\2x
\end{pmatrix}$$
$$\frac{\mathrm d f_1}{\mathrm dx_i}= \begin{pmatrix}
0\\
3 \\
1
\end{pmatrix}$$
## Hesse-Matrix
- Sei $f: D \subseteq \mathbb R^n \to \mathbb R$ eine zweimal differenzierbare Funktion
- Die zweite Ableitung von $f$ ist eine $n \times n$ Matrix namens Hess Matrix
- Den Eintrag an Stelle $i,j$ bezeichnet man $\frac{d^2 f}{d x_ix_j}$ oder $\frac{\delta^2f}{\delta x_i^2}$ falls $i = j$
###### Beispiel
- Ich schreibe als $f_{ab}$ eine Funktion $f$, zunaechst nach $a$ und dann nach $b$ abgeleitet
- Die Hess Matrix einer Funktion $f$ mit den Variablen $x, y, z$ sieht aus wiefolgt
$$\begin{pmatrix}
f_{xx} & f_{xy} & f_{xz} \\
f_{yx} & f_{yy} & f_{yz} \\
f_{zx} & f_{zy} & f_{zz}
\end{pmatrix}$$
## Satz von Schwarz
- Seinen $D \subseteq \mathbb R$ offen, und $f: D \to \mathbb R$ zweimal stetig differenzierbar, gilt:
$$\forall x\in D: \space i, j=1,...n: \frac{\mathrm d^2f}{\mathrm d x_ix_j}= \frac{\mathrm d^2f}{\mathrm d x_jx_i}$$
- Die Hess Matrix ist also immer symmetrisch
# Definitionen
## Gradient
- Sei $D \subseteq \mathbb R^n$ offen, und $f:D \to \mathbb R^n$ differenzierbar
- Man nennt die Ableitung den Gradient von $f$
## Divergenz
- Sei $D \subseteq \mathbb R^n$ offen und $f: D \to \mathbb R^n$ differenzierbar, so ist die Divergenz:
$$\sum_{j = 1}^n \frac{\delta f_j}{\delta x_j}$$
## Laplacian
- Sei $D \in R^n$ und $f: D \to \mathbb R^n$ und zweimal differenzierbar, so ist der Laplacian von $f$
$$\sum_{j = 1}^n\frac{\delta^2f}{\delta x^2_j}$$
## Taylorentwicklung 2. Grades in $\mathbb R^n \to \mathbb R$
- Sei $D \subseteq \mathbb R^n$ offen, $x_0 \in D$ und $f: D\to \mathbb R$ in $x_0$ zweimal differenzierbar dann gilt 
$$\lim_{x \to x_0}\frac{f(x)-f(x_0)\langle Df(x_0), (x-x_0)\rangle-\frac 12 (x-x_0)^t D^2 f(x_0)(x-x_0)}{||x-x_0||^2}=0$$
# Extremumpunkte Suchen
- Sei $A \in \mathbb R_{n \times n}$ eine symmetrische Matrix
- $A$ heisst positiv definit, falls 
$$\forall v \in \mathbb R^n, v \neq 0, v^TAv >0$$
- A heisst positiv semidefinit, falls 
$$\forall v \in \mathbb R^n, v \neq 0, v^TAv \ge 0$$
## Satz ueber Extrema
- Sei $f:D \to \mathbb R$ zweimal differenzierbar und sei $x_0 \in D$ ein innerer Punkt
- Falls $x_0$ ein lokales Extremum fuer $f$ ist, dann ist $Df(x_0)=0$
- Falls $Df(x_0)=0$ und $D^2f(x_0)$ positiv definit ist, dann ist $x_0$ ein lokales Minimum fuer $f$
- Falls $Df(x_0)=0$ und $D^2f(x_0)$ negativ definit ist, dann ist $x_0$ ein lokales Maximum fuer $f$