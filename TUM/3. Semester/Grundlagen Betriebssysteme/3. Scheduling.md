# Dispatching
- Der Dispatcher ist verantwortlich fuer Zustandsuebergaenge von rechenwillig nach rechnend
- Er schaltet den Zustand eines rechnenden Prozesses auf wartend oder rechenwillig, speichert dessen Kontext, laedt den Kontext eines anderen Prozesses und setzt dessen Zustand auf rechnend
- Das switchen zwischen Prozessen ist Insbesondere aufwendig, wenn ein Prozess ueber einen umfangreichen Kontext verfuegt
# Scheduling
- Der Scheduler waehlt den naechsten auszufuehrenden Prozess aus
- Dabei wird das Prozessverhalten beruecksichtigt, zB. die CPU und I/O Nutzung
## Scheduling Klassen
### nicht-unterbrechendes Scheduling
- Bei nicht-unterbrechendem Scheduling werden Prozesse ausgefuehrt bis sie blockieren oder yielden
### unterbrechendes Scheduling
- Bei unterbrechendem Scheduling werden Prozesse bei bestimmten Ereignissen (zB vergehen einer bestimmten Zeit) unterbrochen
- Damit kann man das verhungern anderer Prozesse vermeiden und man sorgt fuer mehr Fairness
## Scheduling Strategien
- Fuer verschiedene Systeme eignen sich unterschiedliche Strategien
- Scheduler zielen im Allgemeinen Fairness zwischen Prozessen und Balance zwischen Systemressourcen an 
### Batch Systeme
- Prozesse werden in der Erzeugungsreihenfolge oder nach ihrer verbleibenden Laufzeit ausgefuehrt
#### Strategien
- First Come First Served und Shortest Job First sind nicht unterbrechend
- Bei Shortest Remaining Time Next wird unterbrochen, wenn ein neuer Prozess mit kuerzerer Rechenzeit eintrifft
### Interaktive Systeme
- In interaktiven Systemen sollten mehrere Prozesse nebenlaeufig zum rechnen kommen
#### Strategien
- Bei Round Robin werden Prozesse deshalb in einer Queue verwaltet, nach einem Zeitquantum unterbrochen und dann wieder hinten angereiht
- Bei Priority Scheudling wird Prozessen eine Prioritaet zugeordnet, gemaess der sie abgearbeitet werden
- Bei Dynamischen Prioritaeten wird die Prioritaet rechnender Prozesse verringert und die von wartenden Prozessen erhoeht
- Auch das I/O Verhalten spielt dabei eine Rolle
### Echtzeit Systeme
- Man unterscheidet zwischen weichen und harten Echtzeitsystemen
- Bei harten Systemen muessen Deadlines getroffen werden, bei weichen werden Ueberschreitungen toleriert
- Weiters unterscheidet man zwischen unkritischen und zeitkritischen Prozessen
- Zeitkritische Prozesse muessen die Deadline treffen, unkritische duerfen nicht verhungern
#### Strategien
- Earliest Deadline First funktioniert aehnlich wie Priority Scheduling, wobei die Deadlines als Priorities funktionieren
- Je nachdem wie Neuankuenfte gehandhabt werden, kann es unterbrechend oder ununterbrechend implementiert werden
- Rate Monotonic Scheduling wird fuer periodische Prozesse (beispielsweise bei Ablaufsteuerung) verwendet um Abschaetzungen zu erlauben, ob Deadlines von Anwendungen getroffen werden koennen
### Multi Level Scheduling
- Bei Multi Level Scheduling werden Prozesse in verschiedene Gruppen mit unterschiedlichen Anspruechen geteilt
#### Short Term Scheudling
- Short Term Scheduling ist die Entscheidung, welcher Prozess als naechstes ausgefuehrt werden soll
- Hier spielen die Scheduling Klassen und Verfahren eine Rolle
- Meist ist der Dispatcher teil des STS
#### Medium Term Scheduling
- Im MTS wird entschieden, ob Prozesse in den Speicher gelagert werden sollten
#### Long Term Scheduling
- Das Ziel des Long Term Schedulers ist, Balance zwischen Systemressourcen zu schaffen
- Wenn ein neuer Prozess Erzeugt wird entscheidet der LTS, ob der Prozess in die Ready-Queue gegeben werden soll
### Multicore/ -prozessorscheduling
#### Time Sharing
- Bei Time Sharing Scheduling werden Ressourcen abwechselnd verwendet
- Abhaengige Prozesse machen langsame Fortschritte
#### Space Sharing
- Abhaengige Prozesse werden gemeinsam gescheduled und bis zur Terminierung laufen gelassen
- Unterbrechungen in der Laufzeit werden vermieden
- Wartezeiten sind oft hoch, und es werden nicht alle Ressourcen verwendet
#### Gang Scheduling
- Bei Gang Scheduling bilden abhaengige Prozesse eine Gang
- Gangs bekommen Zeitscheiben zugewiesen
- Gang Scheduling ist eine Kombination aus Time und Space Sharing
### CPU Warteschlangen
- Prozesse warten entweder in einer globalen Queue auf CPUs, oder jede Queue besitzt eine eigene Queue
#### globale Queues
- Bei globalen Queues ist die CPU Auslastung hoch und Prozesse werden fair behandelt
- Allerdings ist die Cache Lokalitaet beeintraechtigt
![[global Queue.png]]
#### lokale Queues
- Lokale Queues bieten bessere Cache Lokalitaet sowie eine einfache Implementierung und Skalierbarkeit
- Die CPUs sind aber ungleich ausgelastet und Prozesse an stark ausgelasteten CPUs erhalten seltener Rechenzeit
![[local Queues.png|500]]
#### hybride Queues
- bei hybriden Queues werden Prozesse aus lokalen Queues in eine globale verschoben, wenn notwendig
- Dadurch erzielt man eine gute CPU Auslastung
- Da Prozesse meist zu der gleichen Recheneinheit zurueckkehren ist die Cache Lokalitaet ebenso gut
- Die Implementierung ist kompliziert
![[CPU Queue.png]]
# Rechenzeitfaktoren von Prozessen
- Die Rechenzeit eines Prozesses haengt stark von den verwendeten Prozessoren ab
- Je nach Cache- und Temperaturmanagement aendern sich die Laufzeiten
- Die Zugriffe auf den Arbeitsspeicher dauern ebenso fuer unterschiedliche Prozesse unterschiedlich lang