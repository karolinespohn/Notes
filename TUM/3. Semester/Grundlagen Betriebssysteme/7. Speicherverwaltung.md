# Von Neumann
![[von Neumann.png|300]]
- In der von-Neumann Architektur ist die CPU durch das Bussystem mit dem Ein-/Ausgabewerk und dem Speicherwerk verbunden
- Das Bussystem bildet jedoch einen Flaschenhals, weshalb Zugriffe auf den Hauptspeicher teuer sind
- Um den von-Neumann Flaschenhals zu reduzieren, implementieren Betriebssysteme Speicherhierarchien
![[Speicherhierarchie.png|400]]
# Adressraeume
- In gewissen Systemen haben alle Programme vollen Zugriff auf den gesamten physischen Speicher
- Dadurch koennen aber einzelne Prozesse den gesamten Hauptspeicher belegen, oder dem Betriebssystem oder anderen Prozessen im Weg stehen
- Fuer gewoehnlich abstrahiert man deshalb den physischen Adressraum, sodass jeder Prozess einen eigenen, isolierten Prozessraum erhaelt
- Mit einer Abbildung werden virtuelle Speicheradressen auf physische abgebildet
## Diskrete Adressierung
- Bei der diskreten Adressierung entsprichrt die virtuelle Adresse der physischen Adresse
### Extensives Swapping
- Bei einer Umsetzung mittels extensiven Swappings ist stets nur ein Programm im Speicher
- Will man ein anderes Programm ausfuehren, muss das alte Programm auf die Festplatte geladen werden und das neue von der Festplatte geholt werden
### Relokation
- Bei der Relokation werden die Adressen in Programmen umgeschrieben, sodass sie den richtigen Adressen im physischem Speicher entsprechen
- Dabei hat aber noch immer jedes Programm Zugriff auf den gesamten Hauptspeicher und kann somit andere Programme stoeren
## Basisadressierung
- Fuer jeden virtuellen Adressraum wird eine Basisadresse $b_x$ festgelegt
- Die physische Adresse berechnet sich durch die Addition der virtuellen Adresse und der Basisadresse
## Segmentaddressierung
- Bei der Segmentadressierung wird der Adressraum in logische Segmente, beispielsweise fuer Code, Stack und Daten unterteilt
- Fuer jedes Segment braucht man die Startadresse als Basisadresse und die Laenge des Segments
- Beispielsweise koennen die Segmente in einer Tabelle mit Basisadresse, Laenge und Flags gehandhabt werden
![[Segmentadressierung.png|400]]
- Ist der Speicher voll, werden Prozesse temporaer auf die Festplatte gelagert
# Datenstrukturen fuer die Speicherverwaltung
## Bitmap
- Der Speicher wird in Bloecke gleicher Bloecke geteilt
- Mittles einer Bitmap wird der Speicher indexiert, wobei ein bit einem Block entspricht
- Ist der Block besetzt, so wird das bit auf $1$ gesetzt, sonst auf $0$
![[Bitmap.png|400]]
- Werden die Bloecke zu gross gewaehlt, kann es zu einer Verschwendung von Speicherplatz kommen
- Werden die Bloecke zu klein gewaehlt, so ist die Bitmap zu gross
- Bitmaps erlauben einfachen Zugriff, aber die Suche nach freiem Speicher ist aufwendig
## Verkettete Listen
- Alternativ kann man eine verkettete Liste verwenden
- Fuer jeden Bereich im Speicher wird jeweils die Startadresse, Laenge und Belegung gespeichert
![[Verkettete Liste.png|400]]
- Die Speicheraufteilung ist dadurch flexibel, das finden von freiem Speicherbereich aber noch immer aufwendig
- Besser ist, zwei Listen fuer belegten und freien Speicher, oder Baeume zu nutzen, oder die Eintraege nach Speichergroesse zu sortieren
# Belegungsstrategien
- Zur Auswahl eines freien Speicherbereiches werden verschiedene Strategien verwendet
## First-Fit und Next-Fit
- Bei First-Fit wird der erste ausreichend grosse Speicherplatz gewaehlt
- Bei Next-Fit wird der naechste ausreichend grosse Speicherplatz nach dem zuletzt ausgewaehlten Speicherplatz gewaehlt
## Best-Fit und Worst-Fit
- Bei Best-Fit wird der Speicherbereich mit dem geringsten Verschnitt gewaehlt
- Bei Worst-Fit wird der Speicherbereich mit dem groessten Verschnitt gewaehlt
## Buddy-Algorithmus
- Gegeben einem Speicherbereich der Groesse $2^u$
- Ist $2^{u-1} < x < 2^u$, wird der gesamte freie Speicher fuer $x$ alloziiert
- Sonst wird der Bereich in $2$ Bloecke ("Buddies") der Groesse $2^{u-1}$ halbiert
- Man waehlt jeweils einen der Bloecke und halbiert ihn so lange in Bloecke der Groesse $2^{u - n}$, bis gilt $2^{u-n-1} < x < 2^{u-n}$
- Dabei gibt es fuer jede Zweierpotenz eine Liste mit Speicherbereichen in der Groesse
### Vorteile
- Implementierung sowie Suchen nach freien Speicherbereichen ist effizient
- Verschnitt ist maximal ein halber Block
- Buddies koennen effizient verschmolzen werden
### Nachteile
- Benachbarte Bereiche werden teils nicht verschmolzen
# Fragmentierung
## Interne Fragmentierung
- Beim alloziieren von Speicher wird meist mehr Speicher als noetig vergeben
- Als interne Fragmentierung bezeichnet man den Verschnitt, der beim alloziieren entsteht
## Externe Fragmentierung
- Durch die Dynamik beim Anlegen und Freigeben von Speicherbloecken koennen Loecher im Hauptspeicher entstehen
- Somit kann passieren, dass es keinen ausreichend grossen Bereich gibt, obwohl insgesamt geung freier Speicher zur Verfuegung steht
# Virtueller Speicher
- Der virtuelle Adressraum eines Prozesses kann auf unterschiedliche freie Bereiche aufgeteilt werden
## Paging
- Virtuelle Adressraeume werden in Pages aufgeteilt
- Der Hauptspeicher wird in Kacheln geteilt
- Pages und Kacheln sind meist gleich gross
- Durch die MMU werden Pages auf Kacheln gemappt 
![[Paging.png|300]]
### Page Tables
- Pro Prozess gibt es dabei einen Page Table, in der die Verwaltung der Zuordnung von Seiten auf Kacheln 
- Die Startadresse eines Page Tables wird bei Kontextwechsel in die CPU geladen
- Eine virtuelle Adresse $v$ wird im Page Table repraesentiert wiefolgt:
$$v = (s, w)$$
- Dabei ist $s$ die Seitennummer und $w$ der Offset
#### Flags
- Verschiedene Flags stellen verschiedene Informationen zur Verfuegung
- Die $P$-Flag (Present) geben an, ob die physischen Adressen vorhanden sind
- Die $U/S$-Flag (User/Supervisor) geben an ob nur der Kernel die Seite lesen/schreiben darf
- Die $R$-Flag (Referenced) wird gesetzt, sobald auf die Seite zugegriffen wurde
- Die $M$-Flag (Modified) wird gesetzt, sobald in dem Frame geschrieben wurde
- Die $XD$-Flag (execute-disable) legt fest, ob die CPU in diesem Frame gespeicherte Bytes als Instruktionen ausfuehren darf
### Page Faults
- Wird auf eine Adresse zugegriffen, die in keiner Kachel eingelagert ist, so kommt es zu einem Page Fault und es kommt zu einem Interrupt
- Ist die Seite ausgelagert, so muss sie vom Betriebssystem eingelagert werden
- Sind alle Kacheln besetzt, muss eine Seite ersetzt werden
- Ist die Seite nicht ausgelagert, so kommt es zu einem Segmentation Fault
### Einlagerungen
- Das Einlagern von Seiten kann entweder On-Demand erfolgen oder Seiten koennen geprefetched werden
- Fuer die Seiteneinlagerung werden verschiedene Strategien zur Hand gezogen
#### FIFO-Algorithmus
- Bei der FIFO Strategie wird jeweils die Seite ausgelagert, die als erstes eingelagert wurde
- Die Seite die am laengsten im Speicher liegt wird aber unter Umstaenden noch immer regelmaessig genutzt
#### Second-Chance-Algorithmus
- Der Second Chance Algorithmus ist eine Modifikation des FIFO Algorithmus
- Ist bei der aeltesten Seite die $R$-Flag gesetzt, so wird die Flag geloescht und die Seite wieder an die Ende der Queue gestellt
- Sonst wird Inhalt zurueckgeschrieben, falls die $M$-Flag gesetzt ist, bzw die verworfen wenn nicht
#### Clock-Algorithmus
![[Clock Algorithmus.png|300]]
- Ein Zeiger verweist auf die aelteste Seite
- Ist das $R$-Bit dieser Seite nicht gesetzt, wird sie ersetzt
- Ansonsten wird so lange das $R$-Bit auf $0$ gesetzt, und der Zeiger nach vorne verschoben, bis eine Seite mit $R=0$ gefunden wurde
- Je nachdem ob das $M$-Bit dieser Seite gesetzt ist wird der Inhalt zurueckgeschrieben oder verworfen
#### Least-Recently-Used
- Seiten die lange nicht genutzt wurden, werden voraussichtlich auch in naher Zukunft nicht verwendet
- Ansich ist dies eine gute Strategie, aber fuer die Umsetzung ist spezielle Hardware notwendig
#### Not-Recently-Used
- Bei der Not-Recently-Used Strategie gibt es pro Seite $p$ einen Softwarecounter $A_p$
- Die Seite mit dem niedrigsten Counter wird ausgelagert
- Um festzuhalten, wann die Zugriffe waren, werden Aging verfahren verwendet
- Dabei wird der Counter nach einem gewissen Zeitquantum um eins nach rechts geshifted
- Das $R$-Bit wird auf das linkeste Counter Bit addiert
### Abgrenzung: Paging und Swapping
- Als swapping bezeichnet man das auslagern eines Prozesses aus dem Hauptspeicher
- Paging ist feingranularer, da immer nur einzelne Seiten ausgelagert werden
### MMU
- Adressabbildungen sind teuer, da der Page Table im Hauptspeicher liegt
- Deshalb nutzt man den Translation Lookaside Buffer (TLB), einen Cache als Teil der MMU
![[TLB.png|300]]
### Mehrstufiges Paging
- Page Tables werden teils in mehrere kleine Tables unterteilt
- Fuer die Ausfuehrung eines Prozesses muss dann nur ein kleiner teil des urspruenglichem Tables im Hauptspeicher liegen
![[Mehrstufige Page Tables.png|300]]
### Working-Set
- Das Working Set sind die Seiten die ein Prozess aktuell benoetigt
- Zu einem Zeitpunkt $t$ bezeichnen wir das Working Set der letzten $k$ Zugriffe als: $w(k, t)$
- Wegen des Lokalitaetsprinzips bleibt das Working Set eines Prozesses eine Zeit lang gleich
- Moeglichst viel vom Working Set sollte eingelagert sein, sonst kommt es zu Seitenflattern (="thrashing")
- Ziel des Betriebssystems ist Thrashing zu vermeiden, Multiprogramming zu unterstuetzen und das Working Set  eines Prozesses durch Prepaging bereitzuhalten
#### Working-Set Modell
##### Setup
- Im Working-Set Modell werden nur Seiten ersetzt, die nicht im aktuellen Working-Set sind
- Protokollieren von Speicherzugriffen ist teuer, weshalb man das Working Set ueber Rechenzeit approximiert
- $\tau$ ist ein Intervall in der Rechenzeit und $I$ ist ein gewaehltes Intervall, fuer das ueblicherweise gilt $I < \tau$
- Ein Zaehler $Z$ hilft bei der Approximation der Rechenzeit eines Prozesses
- Weiters gibt es fuer jede Seite $p$ einen Zaehler $Z_p$ fuer die Approximation der letzten Zugriffszeit
##### Ablauf
- Nach Ablauf von $I$ wird das Working-Set neu berechnet und die $R$ bits werden auf $0$ gesetzt
- Kommt es zu einem Page Fault, wird eine Seite ersetzt, die nicht im Working Set ist
- Eine Seite ist im Working Set, wenn gilt $R=1$, oder $Z - Z_p \le \tau$
- Ist jede Seite im Working-Set wird die aelteste Seite ersetzt, also die mit dem geringsten $Z_p$
##### Clock Verwaltung
- In Praxis wird meist ein Working-Set Algorithmus mit Clock-artiger Seitenverwaltung verwendet
![[Clock-artiges Working-Set Verfahren.png|300]]
### Verzoegerungen beim Paging
- Da Festplattenzugriffe teuer sind, gibt es Optimierungsversuche
- Das Lesen einer zu ladenden Seite ist schwer zu optimieren, da Wissen ueber folgende Zugriffe erforderlich ist
- Eine Optimierungsmoeglichkeiten stellt Prefetching dar
- Zuletzt wenig oder nicht verwendete Seiten sind bekannt, weshalb praeventives Schreiben moeglich ist
#### 2-Handed-Clock Algorithmus
- Fuer den 2-Handed-Clock Algorithmus verwendet man zwei Zeiger
- Der erste Zeiger fuehrt den normalen Clock- oder Working-Set Algorithmus aus
- Der zweite Zeiger wird von einem Paging-Daemon gefuehrt
- Findet er modifizierte Seiten, schreibt er sie auf die Festplatte zurueck
- Dadurch stehen immer freie Seiten zur Verfuegung
### Rolle des Betriebssystems
- Bei der Erzeugung eines Prozesses ermittelt das Betriebssystem dessen Speicherbedarf und legt Seitentabellen an
- Bei der Ausfuehrung eines Prozesses werden Seitentabellen geladen, die MMU konfiguriert und unter Umstaenden wird Prepaging betrieben
- Bei Page Faults wird die fehlende Seite bestimmt, geladen und die Instruktion die den Fehler verursacht hat erneut ausgefuehrt
- Terminiert ein Prozess, wird dessen Page Table und Sekundaerspeicher freigegeben