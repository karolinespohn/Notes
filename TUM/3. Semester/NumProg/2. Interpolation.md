# Einfuehrung
- Ist ein $f(x)$ unbekannt oder schwer zu berechnen, kann man sich durch eine Approximation $p(x)$ annaehern
- Dabei sollte es eine Schranke geben, die nicht von $f-p$ ueberschritten wird
## Interpolation
- Art der Approximation, bei der $f$ und $p$ an gewissen Punkten gleich sein muessen
- Zu endlich vielen gegebenen Tupeln aus Eingabe und Ergebnis soll eine kontinuierliche Funktion gefunden werden
# Lineare Interpolation
- Bei der linearen Interpolation verbindet man benachbarte Stuetzstellen mit einer Gerade
$$p_i(x) = (x-x_i)\cdot \frac{y_{i+1}-y}{x_{i + 1}-x_i}+y_i$$
# Polynomielle Interpolation
- Bei der polynomiellen Interpolation verwendet man ein Polynom um die unbekannte Funktion anzunaehern
- Um $n + 1$ Stuetzpunkte zu treffen verwendet man haeufig Polynome vom Grad $n$
## Interpolationsfehler 
- Verwendet man $p$ zwischen zwei Stuetzpunkten, so treten Fehler auf:
- Man nennt die Differenz $f(x)-p(x)$ Fehlerterm bzw Rest
$$|f(x)-p(x)| = \left | \frac{f^{(n)}(\xi)}{n!} \cdot \prod_{k =0}^{n  -1}(x-x_k)\right |$$
## Konstruktion einer Interpolierenden
### Lineares Gleichungssystem
- Gegeben seien die Basisfunktionen $g_i$
- Jedes Polynom laesst sich darstellen als:
$$\sum_{i = 0}^{n} a_ig_i(x)$$
- Man kann die Koeffizienten $a_i$ durch ein [[3. Lineare Gleichungssysteme|lineares Gleichungssystem]] bestimmen wiefolgt:
$$\begin{pmatrix}
g_0(x_0) & ... & g_n(x_0) \\
\vdots & \ddots & \vdots \\
g_0(x_n) & ... & g_n(x_n)
\end{pmatrix} \cdot \begin{pmatrix}
a_0 \\
\vdots \\
a_n
\end{pmatrix} = \begin{pmatrix}
y_0 \\
\vdots \\
y_n
\end{pmatrix}$$
### Lagrange Polynome
- Bei der Lagrange Interpolation dienen die Lagrange Polynome $L_k(x)$ als Basisfunktionen
- Man bestimmt diese wiefolgt:
$$L_k(x)=\prod^{n}_{i = 0; i \ne k} \frac{x - x_i}{x_k-x_i}$$
- Fuer die Lagrange-Polynome gilt:
$$L_k(x_i) = \cases{1, \quad \text{falls i = k}\\
0, \quad \text{falls i $\neq$ k}}$$
- Die Interpolante $p$ berechnet man wiefolgt
$$p(x):=\sum^{m}_{j=0}y_j\cdot L_j(x)$$
### Aitken-Neville Algorithmus
- Wird dann verwendet, wenn nur das Ergebnis von $p(x)$ fuer spezielle $x$ benoetigt wird, aber keine explizite Representation von $p$
- Es handelt sich um einen rekursiven Algorithmus
$$p[i, k] = p[i, k - 1] + \frac{x - x_i}{x_{i + k} - x_i} \cdot (p[i + 1, k - 1] - p[i, k - 1])$$
- Man kann bei dem Verfahren problemlos neue Punkte hinzufuegen, unabhaengig von der Lage
###### Beispiel:
![[Aitken Neville.png|300]]
### Newton Algorithmus
- Beim Newton Algorithmus wird eine explizite Repraesentation von $p$ aufgestellt
- Aitken-Neville eignet sich besser, wenn dies nicht benoetigt wird
- Die Koeffizienten werden rekursiv wiefolgt definiert:
$$c_{i,0} = f(x_i) = y_i$$
$$c_{i,1} = \frac{y_{i+1}-y_i}{x_{i+1}-x_i}$$
$$c_{i,k} = \frac{c_{i+1, k-1}-c_{i, k-1}}{x_{i+k}-x_i}$$
- Das Polynom wird gebildet durch: 
$$p(x) = \sum_{i = 0}^n c_{0, i} \space \cdot \prod_{k = 0}^{i - 1} x - x_k$$
- Man kann bei dem Newton Verfahren problemlos neue Punkte hinzufuegen, unabhaengig von der Lage
###### Beispiel:
![[Newton Interpolation.png|300]]
## Runge-Effekt
- Insbesondere bei aequidistanten Stuetzpunkten, ist die Interpolante an den Raendern schlecht konditioniert
- Dementsprechend sollten mehr Stuetzpunkte an die Raender platziert werden
![[Runge Effekt.png|400]]
## Kondition
- Je mehr Punkte interpoliert werden muessen, desto schlechter ist die Kondition
- Will man also die Genauigkeit durch mehr Stuetzstellen verbessern, verschlechtert sich die Kondition
# Hermite-Interpolation
- Um zu vermeiden, dass die Kondition bei hohem Grad zu schlecht wird, kann man mehrere Polynome niedrigen Grades aneinanderkleben
- Bei der Hermit Interpolation wird zwischen zwei Punkten in der Regel ein kubisches Teilpolynom definiert
- Die Interpolante muss stetig und differenzierbar sein
## Vorgang
- Gegeben sind die Werte $x_0, x_1, y_0, y_1$ sowie $y_0'$ und $y_1'$
- Das bedeutet, eine Funktion muss an ihren Intervallgrenzen sowohl mit den Werten $y_i, y_{i + 1}$, als auch mit den Ableitungswerten $y'_i, y'_{i+1}$ uebereinstimmen
- Die Form eines kubischen Polynoms ist im Allegmeinen:
$$p_i(t)= a_3t^3 + a_2t^2 + a_1t + a_0$$
- Um die Funktion richtig auf das Intervall $[x_i, x_j]$ zu skalieren verwendet man folgende Rechnung:
$$t_i(x)= \frac{x-x_i}{x_{j}-x_i} = \frac{x-x_i}{h_i}$$
-  Man schreibt die skalierte Interpolante wiefolgt:
$$p_i(t) = y_i(1 - 3t^2 + 2t^3) + y_{i + 1}(3t^2 - 2t^3) + h_i \cdot (y_i'(t - 2t^2 + t^3) + y_{i + 1}'(-t^2 + t^3)$$
- Durch die stueckweise Interpolation wird der Runge Effekt vermieden
## Splines
- Bei Polynom Splines gibt es die zusaetzliche Forderung, dass die Funktion an jeder Stelle zweimal differenzierbar ist
- Aus $p_i''(1) = p_{i + 1}''(0)$ folgt:
$$\begin{pmatrix}
4 & 1 & & & \\
1 & 4 & \ddots & \\
& \ddots & \ddots & 1 \\
& & 1 & 4
\end{pmatrix} \begin{pmatrix}
y_1' \\ y_2' \\ \vdots \\ y_{n - 2}' \\ y_{n - 1}'
\end{pmatrix} = \frac{3}{h} \begin{pmatrix}
y_2 - y_0 \\ y_3 - y_1 \\
\vdots \\
y_{n - 1} - y_{n - 3} \\ y_n - y_{n - 2} 
\end{pmatrix} - \begin{pmatrix}
y_0' \\ 0 \\
\vdots \\
0 \\ y_n'
\end{pmatrix}$$
- Hierdurch lassen sich die Ableitungswerte $y_i'$ bestimmen und die Intervallfunktionen ermitteln
### Lokale Segmente
- Fuer jedes Intervall $[x_i, x_{i+1}]$ wird ein kubisches Polynom Gesucht
- Dieses wird unter Zurhilfenahme  von $y_i$ und $y_{i+1}$, sowie den ersten Ableitungen an diesen Punkten erstellt
![[lokalel Segmente.png]]
### Globales Aneinanderkleben
- Das gesamte Polynom muss stetig und differenzierbar sein
- Um Stetigkeit zu garantieren muessen die $y$ Werte an den Uebergangsstellen zwischen 2 Intervallen gleich sein
- Um Differenzierbarkeit zu garantieren muss die erste Ableitung an den Uebergangsstellen zwischen 2 Intervallen gleich sein
### Kosten & Performance
- Polynomzuege lassen sich in $O(n)$ arithmetischen Operationen erzeugen
- Lagrange liegt in $O(n^3)$ und Aitken Neville in $O(n^2)$
# Kleinste Quadrate
- Credits fuer diesen Absatz an [Anton](https://github.com/AntonScheitler/Notes) 
- Interpolation ist insbesondere fuer grosse $n$ schlecht konditioniert
- Die [[16. Lineare Ausgleichrechnung|Methode der kleinsten Quadraten]] fordert nicht, dass die Stuetzpunkte exakt getroffen werden, sondern so gut wie moeglich
- Gegeben ist eine Punktwolle $m$, die durch eine Menge von Basisfunktionen $\phi_i$ approximiert wird
- Gesucht ist eine Funktion $f(x) = a_1\phi_1 + ... + a_n \phi_n$, durch die die Punktwolke moeglichst genau approximiert wird
- Es werden die Matrix $A$, sowie die Vektoren $x$ und $v$ festgelegt, sodass gilt:
$$A = \begin{pmatrix}
f_1(x_1) & ... & f_r(x_1) \\
\vdots & & \vdots \\
f_1(x_n) & ... & f_r(x_n)
\end{pmatrix}$$
$$x = (\beta_1, ..., \beta_r)^T$$
$$v = (y_1, ..., y_n)^T$$
- Mithilfe der Normalengleichung kann nun $x$ so bestimmt werden, dass $||v - Ax||$ minimal ist
# Trigonometrische Interpolation
- Bei der trigonometrischen Interpolation werden Funktionen betrachtet, die auf dem komplexen Einheitskreis definiert sind
- Gegeben seien $n$ Knoten auf dem komplexen Einheitskreis mit den Werten $v_0,...,v_{n-1}$
- Durch Linearkombinationen aus Exponentialfunktionen koennen die Punkte interpoliert werden
## Fourier Transformationen
- Fourier Transformationen koennen verwendet werden, um einzelne Frequenzen aus Signalen zu filtern
- Neben der Frequenz wird ein Gewichtungsvektor $c$ bestimmt
### Diskrete Fourier Transformationen DFT
- Gegeben ist ein Vektor $v$ an Frequenzwerten und $\omega = e^{\frac{2\pi i}{n}}$ 
- $c$ wird folgendermassen bestimmt
$$c_k = (DFT(v))_k := \frac 1n \sum^{n-1}_{j=0}v_j\cdot \overline{\omega}^{jk}$$
- Debei ist $k = 0, 1, ..., n-1$
- Man kann dies auch als Matrix-Vektor Multiplikation darstellen: 
$$\begin{pmatrix}
c_0 \\
c_1 \\
\vdots \\
c_{n - 1}
\end{pmatrix} = \begin{pmatrix}
1 & 1 & 1 & ... & 1 \\
1 & \omega^1 & \omega^2 & ... & \omega^{n-1} \\
\vdots & \vdots & \vdots & \vdots & \vdots \\
1 & \omega^{n-1} & \omega^{2(n-1)} & ... & \omega^{(n-1)(n-1)}
\end{pmatrix} \cdot \begin{pmatrix}
v_0 \\
v_1 \\
\vdots \\
v_{n-1}
\end{pmatrix}$$
### Inverse diskrete Fourier Transformationen IDFT
- Bei der Inversen diskreten Fourier Transformation berechnet man die Werte $v_k$ basierend auf Fourierkoeffizienten $c_k$
### Inverse Fast Fourier Transformation
- Bei der schnellen inversen Fourier Transformation teilt man das Problem in eine Sortier- und eine Kombinierphase
#### Sortierphase
- Die Elemente der Vektoren werden aufgeteilt, je nachdem ob ihre Indizes gerade oder ungerade sind:
$$IDFT(c_0,c_2,...c_{n-2})$$
$$IDFT(c_1,c_3,...,c_{n-1})$$
#### Kombinierphase
- In der Kombinierphase werden die Vektoren mithilfe des Butterfly-Operators wieder kombiniert:
![[Butterfly Operator.png|200]]
###### Beispiel:
![[IFFT.png|400]]