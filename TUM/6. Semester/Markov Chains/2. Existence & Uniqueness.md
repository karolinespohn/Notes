# Existence Theorem
- Let $\mu$ be a distribution on $E$, and $\Pi$ be a stochastic matrix on $E$
- There exists a (homogenous) Markov chain $(X_n)_{n=0}^\infty$ with the initial distribution $\mu$ and the transition matrix $\Pi$ 
# Uniqueness Theorem
- Let $E$ be a state space, $\mu$ be distribution on $E$ and $\Pi$ be a stochastic matrix, and let $(X_n)_{n=0}^\infty$ be a stochastic process taking values in $E$
- Then, the following 3 conditions are equivalent: 
	1. $(X_n)$ is a Markov chain with initial distribution $\mu$ and transition matrix $\Pi$
	2. $\forall n \in \mathbb N_0,  \, i_0, i_1,...,i_n \in E:$
	$$  P[X_0 = i_0, X_1 = i_1,..., X_n = i_n] = \mu(i_0) \cdot \Pi_{k = 2}^n \Pi(i_{k-1}, i_k)$$
	3. $\forall A_0, A_1,...,A_n \subseteq E:$
	$$P[X_0 \in A_0, X_1 \in A_1,...,X_n \in A_n] = \sum_{i_0 \in A_0}\mu(i_0) \cdot \sum_{i_1 \in A_1} \Pi(i_0, i_1)\cdot ... \cdot \sum_{i_n}\Pi(i_{n-1}, i_n)$$
- For any two Markov chains $(X_n)_{n \in \mathbb N_0}$ and $(Y_n)_{n \in \mathbb N_0}$ with the same initial distribution $\mu$ and the same transition matrix $\Pi$, their distributions are identical 
