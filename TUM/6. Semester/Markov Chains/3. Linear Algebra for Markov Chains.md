
# Theorem about Markov Property
- Let $(X_n)_{n = 0}^\infty$ be a Markov chain with initial distribution $\mu$ and transition matrix $\Pi$
- Let $m \in \mathbb N_0$ be a point in time and $k \in E$ be a state with $P(X_m = k) > 0$
- Let $\tilde X _n = X_{m + n}$ 
- Let $\tilde P$ be the probability distribution $\tilde P(A)  = P(A |X_m = k)$
- $(\tilde X_n)_{n = 0}^\infty$ is a Markov chain with the transition matrix $\Pi$ and the initial distribution $\delta_k = \cases{1, \quad i = k\\ 0,\quad i \neq k}$ 
# Matrix Multiplication for Distributions
- For a MC $(X_n)_{n \in \mathbb N_0}$ with initial distribution $\mu$ and transition matrix $\Pi$, the distribution of $X_n$ for any number $n \in \mathbb N_0$, is: 
$$\mu^T \cdot \Pi^n$$
- For a MC $(X_n)_{n=0}^\infty$, with the transition matrix $\Pi$, and $P(X_n = j) >0$
$$P(X_{n + m} = i \mid X_n = j) = \Pi^m(j,i)$$
# Properties of $\Pi$
- Since $\Pi$ is a stochastic matrix, the absolute value of all eigenvalues is $\le 1$
- Any $\Pi$ of a Markov Chain has an eigenvector  $\hat \mu$ with the eigenvalue $1$
- ⁠⁠Because of this, the distribution of $\lim_{n \to \infty} X_n = \hat{\mu}$
