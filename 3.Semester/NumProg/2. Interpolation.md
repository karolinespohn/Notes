# Einfuehrung
- Ist ein $f(x)$ unbekannt oder schwer zu berechnen, kann man sich durch eine Approximation $p(x)$ annaehern
- Dabei sollte es eine Schranke geben, die nicht von $f-p$ ueberschritten wird
- Interpolation ist eine Art der Approximation, bei der $f$ und $p$ an gewissen Punkten gleich sein muessen
- Zu endlich vielen gegebenen Tupeln aus Eingabe und Ergebnis soll eine kontinuierliche Funktion gefunden werden
## Begriffe
- Gegeben einer  Funktion $f_d$ und eine Interpolierende $f_i$
- Die Stuetzstellen bzw Abszisse sind die $x$ Werte, an denen $f_d$ definiert ist
- Ordinate sind die $y$ Werte zu den Stuetzstellen
- Paare von Abszissen und Ordinaten $(x_i, y_i)$ heissen Stuetzpunkte
- Die Distanz zwischen zwei Stuetzstellen $h_i = x_{i+1}-x$ heisst Maschenweite
- Ist $h_i=h$ Konstant, so heissen die Knoten Aequidistant
# Polynomielle Interpolation
- Man nennt $p\in \mathbb P_n$ polynomielle Interpolierende zu $f$ mit den Knoten $x_0 <x_1<...<x_n$, wenn gilt:
$$\forall \space i \in \{0, 1, ..., n\} :p(x_i) = f(x_i) :=y_i$$
- Haeufig gilt $deg(p) = n$
- Je mehr Stuetzpunkte gegeben sind, desto schwerer ist die Findung einer Interpolante
## Interpolationsfehler 
- Verwendet man $p$ zwischen zwei Stuetzpunkten, so treten Fehler auf:
- Man nennt die Differenz $f(x)-p(x)$ Fehlerterm bzw Rest
## Konstruktion einer Interpolierenden
### Polynom Basisfunktionen
- gegeben den Basisfunktionen $g_0, g_1,..., g_n$ und den Basispolynomen $P_0, P_1, ...,P_n$ 
- Sei $g'= g_0+g_1+...+ g_n$
- Man loest nun das [[3. Lineare Gleichungssysteme|LGS]] fuer die Funktion $g'$ mit den Inputs $P_0,...P_n$ 
### Lagrange Polynome
- Fuer Lagrange Polynome stellt man die Polynome $L_k$ auf wiefolgt:
$$l_j(x)=\prod^{n}_{i = 0; i \ne j} \frac{x - x_i}{x_j-x_i}$$

- Die Interpolante $p$ berechnet man wiefolgt
$$p(x):=\sum^{m}_{j=0}y_j\cdot l_j(x)$$
### Aitken-Neville Algorithmus
- Wird insbesondere dann verwendet, wenn nur das Ergebnis von $p(x)$ fuer spezielle $x$ benoetigt wird, aber keine explizite Representation von $p$
- Es handelt sich um einen rekursiven Algorithmus
$$p_{i, k}(x)=\frac{x_{i+k}-x}{x_{i+k}-x_i} \cdot p_{i, k-1}(x) + \frac{x-x_i}{x_{i+k}-x_i} \cdot p_{i+1,k-1}(x)$$
- Man kann bei dem Verfahren problemlos neue Punkte hinzufuegen, unabhaengig von der Lage
###### Beispiel:
![[Aitken Neville.png|300]]
### Newton Algorithmus
- Beim Newton Algorithmus wird eine explizite Repraesentation von $p$ aufgestellt
- Aitken-Neville eignet sich besser, wenn dies nicht benoetigt wird
- Die Koeffizienten werden rekursiv wiefolgt definiert:
$$c_{i,k} = \frac{c_{i+1, k-1}-c_{i, k-1}}{x_{i+k}-x_i}$$
$$c_{i,0} = f(x_i) = y_i$$
$$c_{i,1} = \frac{y_{i+1}-y_i}{x_{i+1}-x_i}$$
- Man kann bei dem Newton Verfahren problemlos neue Punkte hinzufuegen, unabhaengig von der Lage
###### Beispiel:
![[Newton Interpolation.png|300]]
## Runge-Effekt
- Insbesondere bei Aequidistanten Stuetzpunkte, ist die Interpolante an den Raendern schlecht konditioniert
- Dementsprechend sollten mehr Stuetzpunkte an die Raender platziert werden
![[Runge Effekt.png|400]]
# Hermite Interpolation
- Polynomielle Interpolation ist fuer grosse Grade schlecht konditioniert
- Ein Loesungsansatz dafuer sind Polynomzuege: Polynome niedrigerer Grade werden aneinandergeklebt
- Bei der Hermit Interpolation wird zwischen zwei Punkten jeweils ein Polynom des Grades $n-1$ definiert, wobei $n$ die Ordnung der Interpolierenden ist
- Die Teilpolynome sind in der Regel kubisch
- Bei der Hermit Interpolation muss die Interpolante stetig und differenzierbar sein
## Vorgang
- Gegeben sind die Werte $x_0, x_1, y_0, y_1$ sowie $y_0'$ und $y_1'$
- Die Form eines kubischen Polynoms ist im Allegmeinen:
$$p_i(t)= a_3t^3 + a_2t^2 + a_1t + a_0$$
- Nachdem man mittels eines [[3. Lineare Gleichungssysteme|LGS]] aber die Koeffizienten gefunden hat, schreibt man das Polynom wiefolgt
- Um die Funktion richtig auf das Intervall $[x_i, x_j]$ zu skalieren verwendet man folgende Rechnung:
$$t_i(x)= \frac{x-x_i}{x_{j}-x_i} = \frac{x-x_i}{h_i}$$
-  Man schreibt die skalierte Interpolante wiefolgt:
$$p_i(t_i(x))= y_i \cdot H_0(t_i(x)) + y_{i+1} \cdot H_1(t_i(x)) + h_i \cdot y_i'\cdot H_2(t_i(x)) + h_{i + 1} \cdot y_{i +1}'\cdot H_3(t_i(x))$$
- Durch die stueckweise Interpolation wird der Runge Effekt vermieden
## Splines
- Bei Polynom Splines gibt es die zusaetzliche Forderung, dass die Funktion an jeder Stelle zweimal differenzierbar ist
- Aus $p_i''(1) = p_{i + 1}''(0)$ folgt:
$$\begin{pmatrix}
4 & 1 & & & \\
1 & 4 & \ddots & \\
& \ddots & \ddots & 1 \\
& & 1 & 4
\end{pmatrix} \begin{pmatrix}
y_1' \\ y_2' \\ \vdots \\ y_{n - 2}' \\ y_{n - 1}'
\end{pmatrix} = \frac{3}{h} \begin{pmatrix}
y_2 - y_0 \\ y_3 - y_1 \\
\vdots \\
y_{n - 1} - y_{n - 3} \\ y_n - y_{n - 2} 
\end{pmatrix} - \begin{pmatrix}
y_0' \\ 0 \\
\vdots \\
0 \\ y_n'
\end{pmatrix}$$
- Hierdurch lassen sich die Ableitungswerte $y_i'$ bestimmen und die Intervallfunktionen ermitteln
### Lokale Segmente
- Fuer jedes Intervall $[x_i, x_{i+1}]$ wird ein kubisches Polynom Gesucht
- unter Zurhilfenahme  von $y_i$ und $y_{i+1}$, sowie den ersten Ableitungen an diesen Punkten erstellt
![[lokalel Segmente.png]]
### Globales Aneinanderkleben
- Das gesamte Polynom muss stetig und differenzierbar sein
- Um Stetigkeit zu garantieren muessen die $y$ Werte an den Uebergangsstellen zwischen 2 Intervallen gleich sein
- Um Differenzierbarkeit zu garantieren muss die erste Ableitung an den Uebergangsstellen zwischen 2 Intervallen gleich sein
### Kosten & Performance
- Polynomzuege lassen sich in $O(n)$ arithmetischen Operationen erzeugen
- Lagrange liegt in $O(n^3)$ und Aitken Neville in $O(n^2)$
# Kleinste Quadrate
- Credits fuer diesen Absatz an [Anton](https://github.com/AntonScheitler/Notes) 
- Interpolation ist insbesondere fuer grosse $n$ schlecht konditioniert
- Die [[16. Lineare Ausgleichrechnung|Methode der kleinsten Quadraten]] fordert nicht, dass die Stuetzpunkte exakt getroffen werden, sondern so gut wie moeglich
- Gegeben ist eine Punktwolle $m$, die durch eine Menge von Basisfunktionen $\phi_i$ approximiert wird
- Gesucht ist eine Funktion $f(x) = a_1\phi_1 + ... + a_n \phi_n$, durch die die Punktwolke moeglichst genau approximiert wird
- Es werden die Matrix $A$, sowie die Vektoren $x$ und $v$ festgelegt, sodass gilt:
$$A = \begin{pmatrix}
f_1(x_1) & ... & f_r(x_1) \\
\vdots & & \vdots \\
f_1(x_n) & ... & f_r(x_n)
\end{pmatrix}$$
$$x = (\beta_1, ..., \beta_r)^T$$
$$v = (y_1, ..., y_n)^T$$
- Mithilfe der Normalengleichung kann nun $x$ so bestimmt werden, dass $||v - Ax||$ minimal ist
# Trigonometrische Interpolation
- Bei der trigonometrischen Interpolation werden Funktionen betrachtet, die auf dem komplexen Einheitskreis definiert sind
- Gegeben seien $n$ Knoten auf dem komplexen Einheitskreis mit den Werten $v_0,...,v_{n-1}$
- Durch Linearkombinationen aus Exponentialfunktionen koennen die Punkte interpoliert werden
## Fourier Transformationen
- Fourier Transformationen koennen verwendet werden, um einzelne Frequenzen aus Signalen zu filtern
- Neben der Frequenz wird ein Gewichtungsvektor $c$ bestimmt
### Diskrete Fourier Transformationen DFT
- Die diskrete Fourier Transformation komplexer Eingabedaten $v=(v_0,v_1,...,v_{n-1})^T$ ist definiert wiefolgt:
$$c_k = (DFT(v))_k := \frac 1n \sum^{n-1}_{j=0}v+j\cdot \overline{\omega}^{jk}$$
- Debei ist $k = 0, 1, ..., n-1$
- Gesucht ist dabei der Vektor $c$ der Gewichte
### Inverse diskrete Fourier Transformationen IDFT
- Bei der Inversen diskreten Fourier Transformation berechnet man die Werte $v_k$ basierend auf Fourierkoeffizienten $c_k$
### Inverse Fast Fourier Transformation
- Bei der schnellen inversen Fourier Transformation teilt man das Problem in eine Sortier- und eine Kombinierphase
#### Sortierphase
- Die Elemente der Vektoren werden aufgeteilt, je nachdem ob ihre Indizes gerade oder ungerade sind:
$$IDFT(c_0,c_2,...c_{n-2})$$
$$IDFT(c_1,c_3,...,c_{n-1})$$
#### Kombinierphase
- In der Kombinierphase werden die Vektoren mithilfe des Butterfly-Operators wieder kombiniert:
![[Butterfly Operator.png|200]]
###### Beispiel:
![[IFFT.png|400]]